<!DOCTYPE html>
<html>
<head>
    <title>音频展示</title>
    <style>
        table {
            width: 100%;
            border-collapse: collapse;
        }
        th, td {
            border: 1px solid black;
            padding: 8px;
            text-align: center;
            white-space: nowrap;
        }
        th {
            background-color: #6699ff;
        }
        .sub-row {
            border-top: none;
        }
         .audio-name {
            position: absolute;
            top: -30px;
            left: 0;
            width: 100%;
            text-align: center;
            font-weight: bold;
        }
        .img-box{
            width:100%;
            heigth:2000px;
            background: url('images/background.png');
            top: 0;
            left: 0;
            margin: 0 0 0 0;
        }
        body{
            margin:10px 200px 10px 200px;
            background-image: url("images/background.png");
            background-size: 100% 200px;
            background-repeat: no-repeat;
        }
    </style>
</head>
<body>
    <h1 id="title" font face="Times New Roman">Demo for One-shot VC Project</h1>
    <h3 id="kind" font face="Times New Roman">Scenario I: both source and target speakers are in the VCTK dataset but not in the trainset.</h3>
    <table>
        <tr>
            <th></th>
            <th>Source Audio</th>
            <th>Target Audio</th>
            <th>Converted Audio</th>
        </tr>
        <tr>
          <td>Female-Male</td>
          <td>
            <audio controls>
                <source src="source/u2u_vctk/p225_005.wav" type="audio/mpeg">
            </audio>
            <br>
            source: p225_005.wav
          </td>
          <td>
            <audio controls>
                <source src="source/u2u_vctk/p226_003.wav" type="audio/mpeg">
            </audio>
            <br>
            target: p226_003.wav
          </td>
          <td>
            <audio controls>
               <source src="source/u2u_vctk/p225_005_p226_003_gen.wav" type="audio/mpeg">
            </audio>
            <br>
            convert: p225_005_p226_003_gen.wav
          </td>
        </tr>
        <tr>
          <td>Male-Female</td>
          <td>
            <audio controls>
                <source src="source/u2u_vctk/p316_241.wav" type="audio/mpeg">
            </audio>
            <br>
            source: p316_241.wav
          </td>
          <td>
            <audio controls>
                <source src="source/u2u_vctk/p262_013.wav" type="audio/mpeg">
            </audio>
            <br>
            target: p262_013.wav
          </td>
          <td>
            <audio controls>
                <source src="source/u2u_vctk/p316_241_p262_013_gen.wav" type="audio/mpeg">
            </audio>
            <br>
            convert: p316_241_p262_013_gen.wav
          </td>
        </tr>
        <tr>
          <td>Male-Male</td>
          <td>
            <audio controls>
                <source src="source/u2u_vctk/p245_011.wav" type="audio/mpeg">
            </audio>
            <br>
            source: p245_011.wav
          </td>
          <td>
            <audio controls>
                <source src="source/u2u_vctk/p227_004.wav" type="audio/mpeg">
            </audio>
            <br>
            target: p227_004.wav
          </td>
          <td>
            <audio controls>
                <source src="source/u2u_vctk/p245_011_p227_004_gen.wav" type="audio/mpeg">
            </audio>
            <br>
            convert: p245_011_p227_004_gen.wav
          </td>
        </tr>
        <tr>
          <td>Female-Female</td>
          <td>
            <audio controls>
                <source src="source/u2u_vctk/p233_015.wav" type="audio/mpeg">
            </audio>
            <br>
            source: p233_015.wav
          </td>
          <td>
            <audio controls>
                <source src="source/u2u_vctk/p234_045.wav" type="audio/mpeg">
            </audio>
            <br>
            target: p234_045.wav
          </td>
          <td>
            <audio controls>
                <source src="source/u2u_vctk/p233_015_p234_045_gen.wav"" type="audio/mpeg">
            </audio>
            <br>
            convert: p233_015_p234_045_gen.wav
          </td>
        </tr>
  </table>
      <h3 id="kind" font face="Times New Roman">Scenario II: neither the source speaker nor the target speaker is in the VCTK dataset.</h3>
  <table>
        <tr>
            <th></th>
            <th>Source Audio</th>
            <th>Target Audio</th>
            <th>Converted Audio</th>
        </tr> 
        <tr>
          <td>Female-Male</td>
          <td>
            <audio controls>
                <source src="source/no_finetune/wang_0045.wav" type="audio/mpeg">
            </audio>
            <br>
            source: wang_0045.wav
          </td>
          <td>
            <audio controls>
                <source src="source/no_finetune/xue_0048.wav" type="audio/mpeg">
            </audio>
            <br>
            target: xue_0048.wav
          </td>
          <td>
            <audio controls>
               <source src="source/no_finetune/wang_0045_xue_0048_gen.wav" type="audio/mpeg">
            </audio>
            <br>
            convert: wang_0045_xue_0048_gen
          </td>
        </tr>
        <tr>
          <td>Male-Female</td>
          <td>
            <audio controls>
                <source src="source/no_finetune/xue_0048.wav" type="audio/mpeg">
            </audio>
            <br>
            source: xue_0048.wav
          </td>
          <td>
            <audio controls>
                <source src="source/no_finetune/wang_0045.wav" type="audio/mpeg">
            </audio>
            <br>
            target: wang_0045.wav
          </td>
          <td>
            <audio controls>
               <source src="source/no_finetune/xue_0048_wang_0045_gen.wav" type="audio/mpeg">
            </audio>
            <br>
            convert: xue_0048_wang_0045_gen.wav
          </td>
        </tr>
  </table>
        <h3 id="kind" font face="Times New Roman">Scenario III: neither the source speaker nor the target speaker is in the dataset, but a small amount of data (about 7.5min) from both is used to finetune the pre-trained model.</h3>
  <table>
        <tr>
            <th></th>
            <th>Source Audio</th>
            <th>Target Audio</th>
            <th>Converted Audio</th>
        </tr> 
        <tr>
          <td>Female-Male</td>
          <td>
            <audio controls>
                <source src="source/wang_0050.wav" type="audio/mpeg">
            </audio>
            <br>
            source: wang_0050.wav
          </td>
          <td>
            <audio controls>
                <source src="source/xue_0048.wav" type="audio/mpeg">
            </audio>
            <br>
            target: xue_0048.wav
          </td>
          <td>
            <audio controls>
               <source src="source/wang_0050_to_xue_0048.wav" type="audio/mpeg">
            </audio>
            <br>
            convert: wang_0050_to_xue_0048.wav
          </td>
        </tr>
        <tr>
          <td>Male-Female</td>
          <td>
            <audio controls>
                <source src="source/xue_0048.wav" type="audio/mpeg">
            </audio>
            <br>
            source: xue_0048.wav
          </td>
          <td>
            <audio controls>
                <source src="source/wang_0050.wav" type="audio/mpeg">
            </audio>
            <br>
            target: wang_0050.wav
          </td>
          <td>
            <audio controls>
               <source src="source/xue_0048_to_wang_0050.wav" type="audio/mpeg">
            </audio>
            <br>
            convert: xue_0048_wang_0050_gen.wav
          </td>
        </tr>
  </table>
</body>
